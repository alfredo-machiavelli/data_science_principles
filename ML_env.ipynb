{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QDMxPNTM-8Ew",
        "NNBbUfy9Fxqg",
        "iAzDSKlBHUQS",
        "yHBVQzeVPs02"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDMxPNTM-8Ew"
      },
      "source": [
        "## EE 461P: Data Science Principles  \n",
        "### Assignment 1  \n",
        "### Total points: 70\n",
        "### Due: Tuesday, February 8, 2022, submitted via Canvas by 11:59 pm  \n",
        "\n",
        "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UT eID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TAs know.\n",
        "\n",
        "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)\n",
        "\n",
        "### Name(s) and EID(s):\n",
        "1. Harshika Jha\n",
        "2. Jared McArthur\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1  Machine Learning Environments (5 pts)\n",
        "\n",
        "First, read the Vertex AI description at https://cloud.google.com/vertex-ai\n",
        "and watch the associated video https://www.youtube.com/watch?v=gT4qqHMiEpA&t=216s.\n",
        "\n",
        "Now state what you feel are the top three capabilities that Vertex AI provides to facilitate the design and deployment of ML solutions (the answer is subjective of course; the intent is make you think about the various steps involved in the design pipeline)."
      ],
      "metadata": {
        "id": "2l4ZpGDS0bVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 1"
      ],
      "metadata": {
        "id": "qaijrS9q8_go"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNBbUfy9Fxqg"
      },
      "source": [
        "# Question 2 (20 pts)\n",
        "\n",
        "A biased coin, with an unknown but fixed probability $p$ of obtaining \"tails\" on any toss (independent of the outcomes of other tosses), is tossed  8 times, and the following  sequence of outcomes is observed:\n",
        "\n",
        "1 1 1 0 1 0 0 1 \n",
        "\n",
        "where 0 denotes heads and 1 denotes tails. Derive the  maximum likelihood estimate of $p$ given the observation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 2"
      ],
      "metadata": {
        "id": "LJ_Kz4VN9Dus"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHBVQzeVPs02"
      },
      "source": [
        "# Question 3 (15 pts)\n",
        "\n",
        "Let variables $x\\in R^{\\ p}$ and $y \\in R$ be related by the following equation\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "y=\\phi(w,x) +\\epsilon\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where $\\phi(w,x): R^{\\ p}\\rightarrow R$ , with learnable parameter $w \\in R^{\\ p}$, denotes a deterministic function of the predictor variable $x$, and the zero-mean scalar random variable $\\epsilon$ has the distribution\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "f_{Î•}(\\epsilon)= \\frac{1}{2b} \\exp(-\\frac{|\\epsilon|}{b})\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "In other words, the distribution of the target variable $y$ conditioned on the model prediction $\\phi(w,x)$ and noise distribution parameter $b$ is   \n",
        "\n",
        "$$f_{Y|\\phi(w,x),b}(y|\\phi(w,x),b)=\\frac{1}{2b} \\exp(-\\frac{|y-\\phi(w,x)|}{b})$$\n",
        "\n",
        "\n",
        "Now suppose we have data set of size $N$ where the observations $y_1,y_2,...,y_N$ correspond to inputs $x_1,x_2,...,x_N$. Show that the maximum likelihood estimates of $w$ and $b$ are \n",
        "\n",
        "$$w_{ML} =  \\arg \\min_{w}  [\\ \\sum_{i=1}^N|y-\\phi(w,x_i)|\\ ]$$\n",
        "\n",
        "and \n",
        "$$b_{ML}=\\frac{1}{N} \\sum_{i=1}^N|y-\\phi(w_{ML},x_i)|$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UovxZfi8Pt7N"
      },
      "source": [
        "# Answer 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4 : Multiple Linear Regression (MLR) in Python (25 points) \n",
        "\n",
        "In this problem, you will be working on a dataset to predict housing prices in Ames, Iowa. The initial few cells will download and set up the data.\n",
        "\n",
        "The dataset consists of 1460 datapoints. You are required to predict the `SalePrice` using the following 8 features for each datapoint - \n",
        "\n",
        "1. `OverallQual` - Rates the overall material and finish of the house\n",
        "\n",
        "2. `GrLivArea` - Above grade (ground) living area square feet\n",
        "\n",
        "3. `GarageCars` - Size of garage in car capacity\n",
        "\n",
        "4. `GarageArea` - Size of garage in square feet\n",
        "\n",
        "5. `TotalBsmtSF` - Total square feet of basement area\n",
        "\n",
        "6. `1stFlrSF` - First Floor square feet\n",
        "\n",
        "7. `FullBath` - Full bathrooms above grade\n",
        "\n",
        "8. `TotRmsAbvGrd` - Total rooms above grade (does not include bathrooms)\n",
        "\n",
        "You will start writing code from the `Performing Regression` section. "
      ],
      "metadata": {
        "id": "7y3YnK-5JVZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Common Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "h674WcyEWhHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "VXl6YfOzV7Mf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f87SCvoC8vD",
        "outputId": "58b8d552-4c9f-42ef-c3ae-810d91b105b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-20 04:17:21--  https://raw.githubusercontent.com/Data-Science-FMI/ml-from-scratch-2019/master/data/house_prices_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460676 (450K) [text/plain]\n",
            "Saving to: â€˜house_prices_train.csvâ€™\n",
            "\n",
            "house_prices_train. 100%[===================>] 449.88K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-01-20 04:17:21 (19.4 MB/s) - â€˜house_prices_train.csvâ€™ saved [460676/460676]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Download data\n",
        "!wget https://raw.githubusercontent.com/Data-Science-FMI/ml-from-scratch-2019/master/data/house_prices_train.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read data into a pandas dataframe\n",
        "df = pd.read_csv('house_prices_train.csv')"
      ],
      "metadata": {
        "id": "tyCc5B_QWRk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data"
      ],
      "metadata": {
        "id": "4BwuXvbHXMYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "df = df.fillna(0)\n",
        "\n",
        "X = df[[\"OverallQual\",\"GrLivArea\",\"GarageCars\",\"GarageArea\",\"TotalBsmtSF\",\"1stFlrSF\",\"FullBath\",\"TotRmsAbvGrd\"]]\n",
        "y = df[\"SalePrice\"]\n",
        "\n",
        "pd.set_option('display.max_columns', 8)"
      ],
      "metadata": {
        "id": "gmGGRmwmW_Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing Regression"
      ],
      "metadata": {
        "id": "vtKZm6qQmQG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we get into the regression model, it would be good to gain an intuition of the data that we have. We present two plots here - A distribution of the variable to be predicted and a heatmap depicting the correlation between the different dependent variables. Feel free to explore more and perform additional analysis!"
      ],
      "metadata": {
        "id": "ep_6EFCaAaE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. (5 points) Plot a histogram of the `SalePrice` to get an idea of distribution of the variable to be predicted. Mention any interesting observations about the graph, along with any information about outliers. (Hint : Take a look at [`seaborn.displot`](https://seaborn.pydata.org/generated/seaborn.displot.html))"
      ],
      "metadata": {
        "id": "UWQYQ0pr0ps4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer a"
      ],
      "metadata": {
        "id": "_OFFRTb1_9aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. (5 points) Plot a heatmap to show the correlation matrix of the dependent variables (features) that will be used to make predictions. This will help you understand how correlated/uncorrelated different features are and how important they might be for prediction. (Hint : Take a look at [`pandas.Datafram.corr`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) and [`seaborn.heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html))"
      ],
      "metadata": {
        "id": "J2oKZRZj1FjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer b"
      ],
      "metadata": {
        "id": "StPutvokBNeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. (2 pts) Print the shape (number of rows and columns) of the feature matrix X, and print the first 5 rows."
      ],
      "metadata": {
        "id": "CyE8hmhBmiaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer c"
      ],
      "metadata": {
        "id": "ctu1KahKm3QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. (5 pts) Using ordinary least squares, fit a multiple linear regression (MLR) on all the feature variables using the entire dataset. Report the regression coefficient of each input feature and evaluate the model using mean squared error (MSE). Example of ordinary least squares in Python is shown in Section 1.1.1 of http://scikit-learn.org/stable/modules/linear_model.html."
      ],
      "metadata": {
        "id": "ypwnHoBWmoNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer d"
      ],
      "metadata": {
        "id": "IvQ1xh7UnD04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. (5 pts) Split the data into a training set and a test set, using the train_test_split with test_size = 0.25 and random_state = 50. Fit an MLR using the training set. Evaluate the trained model using the training set and the test set, respectively. Compare the two MSE values thus obtained. Report the  ð‘…2  value(coefficient of determination)(https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html and https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) ."
      ],
      "metadata": {
        "id": "Y1nhR779msFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer e"
      ],
      "metadata": {
        "id": "l8oamiA1-T7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. (3 pts) Recall the assumptions behind the MLR model - \n",
        "\n",
        "1. There is a linear relationship between the dependent and the predictor variables\n",
        "\n",
        "2. The residuals (difference between predicted and original values) are normally distributed with a constant variance and independent of each other\n",
        "\n",
        "The correlation matrix plotted earlier can be used to loosely argue independence. For this problem, you are required to build a scatter plot of predicted vs real values of test data so that both axes are equal in length and plot y=x line in the middle. Also, Plot the distribution (histogram) of residuals to justify if you think MLR model is reasonable for this problem or not?"
      ],
      "metadata": {
        "id": "MBWIWHCXpWZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer f"
      ],
      "metadata": {
        "id": "UVHgJHJNB-N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5 : Swapping dependent and independent variables (5 points)"
      ],
      "metadata": {
        "id": "OXX9bgPMDCs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider a dataset consisting of two features and N (>1) data points -\n",
        "\n",
        "1.   The number of ice-cream cones sold per day (Var 1)\n",
        "2.   The average temperature of a day (Var 2)\n",
        "\n",
        "We perform two ordinary least squares regression experiments  -\n",
        "\n",
        "Experiment 1 : We treat Var 1 as the independent variable and Var 2 as the dependent variable.\n",
        "\n",
        "Experiment 2 : We treat Var 2 as the indpendent variable and Var 1 as the dependent variable.\n",
        "\n",
        "Let the slope of the regression line obtained in Experiment 1 be S1 and the slope of regression line obtained in Experiment 2 be S2.\n",
        "\n",
        "Select the most appropriate statement about S1 * S2 (the product of S1 and S2), which is true without making any assumptions about the data-points, from amongst the choices below along with an explanation of why you think that option is true - \n",
        "\n",
        "a) S1 * S2 = -1 \\\\\n",
        "b) S1 * S2 = 1 \\\\\n",
        "c) The value of S1 * S2 cannot be ascertained \\\\"
      ],
      "metadata": {
        "id": "0-wW4aP1JaHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer 5"
      ],
      "metadata": {
        "id": "sxbbnJP83wqV"
      }
    }
  ]
}